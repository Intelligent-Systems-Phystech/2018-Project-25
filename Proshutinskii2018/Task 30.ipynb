{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача №30: Метод построения HG-LBP дескриптора на основе гистограмм градиентов для детектирования пешеходов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагается разработать новый дескриптор, обобщающий LBP дескриптор на основе гистограмм модулей градиентов, имеющий свойства композиции HOG-LBP для задачи детектирования пешеходов на изображении. В качестве анализа качества нового дескриптора предлагается использовать графики ошибок детектирования FAR/FRR на базе INRIA.\n",
    "\n",
    "http://www.machinelearning.ru/wiki/index.php?title=Автоматизация_научных_исследований_в_машинном_обучении_%28практика%2C_В.В._Стрижов%29#.D0.97.D0.B0.D0.B4.D0.B0.D1.87.D0.B0_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Данные:__ База данных пешеходов INRIA: http://pascal.inrialpes.fr/data/human/\n",
    "\n",
    "__Базовой алгоритм:__ Xiaoyu Wang, Tony X. Han, Shuicheng Yan. An HOG-LBP Human Detector with Partial Occlusion Handling \\\\ ICCV 2009\n",
    "\n",
    "__Решение:__ Одним из вариантов обобщения LBP может быть использование вместо гистограмм распределения точек по LBP-коду, гистограмм распределения модулей градиентов точек в блоке по LBP-коду (HG-LBP). Предлагается для основы экспериментов использовать библиотеку OpenCV, в которой реализованы алгоритмы HOG и LBP. Необходимо модифицировать исходный код реализации LBP и вставить подсчет модулей градиента и накопление соответствующей гистограммы по LBP. Необходимо написать программу чтения базы INRIA, обучения по ней метода линейного SVM на исходных и модифицированных дескрипторах, сбора статистики детектирования и построения DET-графиков FAR/FRR.\n",
    "\n",
    "Для работы необходимо установить OpenCV для Python\n",
    "1. Запустить __Anaconda Promt__ от имени администратора\n",
    "2. Ввести __conda install -c conda-forge opencv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# далее задаются параметры HOG-a, они выставлены как в статье.\n",
    "win_size = (64,128) \n",
    "block_size = (16,16)\n",
    "block_stride = (8,8)\n",
    "cell_size = (8,8)\n",
    "nbins = 9\n",
    "deriv_aperture = 1\n",
    "win_sigma = -1\n",
    "histogram_norm_type = 0\n",
    "l2_hys_threshold = 2.0000000000000001e-01\n",
    "gamma_correction = 0\n",
    "nlevels = 64\n",
    "hog = cv2.HOGDescriptor(win_size,block_size,block_stride,cell_size,nbins,deriv_aperture,win_sigma,\n",
    "                        histogram_norm_type,l2_hys_threshold,gamma_correction,nlevels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_stride = (8,8) #шаг скользящего окна в пикселях по ширине и высоте\n",
    "path_to_image = \"INRIAPerson/Train/pos/crop_000010.png\"\n",
    "img = cv2.imread(path_to_image)\n",
    "descriptor = hog.compute(img, win_stride)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В базе INRIA размер изображений содержащих пешеходов  - 96х160(train) и 70x134(test). Человек расположен по центру.\n",
    "\n",
    "Вам нужно получить вектор признаков(дескриптор) для окна 64х128. По умолчанию compute() строит дескрипторы для всех окон размером 64х128 методом скользящего окна, с шагом win_stride по обеим осям. Но если вам нужно получить дескриптор только для одного окна 64х128, то у метода есть аргумент locations, в котором можно передать координаты верхнего левого угла интересующего вас окна (либо список таких координат)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path_to_image)\n",
    "height, width = img.shape[:2]\n",
    "locations = [((width-64)//2, (height-128)//2)]\n",
    "descriptor = hog.compute(img, locations=locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем то же в цикле для всех изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "path_to_pos_images = \"INRIAPerson/Train/pos/\"\n",
    "onlyfiles = [f for f in listdir(path_to_pos_images) if isfile(join(path_to_pos_images, f))]\n",
    "descriptors_pos = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем это в цикле для каждого изображения в папке pos/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Так как все изображения в тесте одинаковые по размеру, то\n",
    "# посчитаем константы вне цикла\n",
    "img = cv2.imread(path_to_pos_images+onlyfiles[0])\n",
    "height, width = img.shape[:2]\n",
    "locations = [((width-64)//2, (height-128)//2)]\n",
    "\n",
    "for im in onlyfiles:\n",
    "    img = cv2.imread(path_to_pos_images+im)\n",
    "    descriptors_pos.append(np.squeeze(hog.compute(img, locations=locations)))\n",
    "    \n",
    "descriptors_pos = np.stack(descriptors_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения фона(отрицательные примеры)  - изображения произвольного размера. В обучающей выборке их 1218. Авторы HOG для обучения выбирали рандомно 10 окон 64х128 из каждого изображения  - всего 12180 примеров, не содержащих пешеходов.\n",
    "\n",
    "Для этого, например, можно посчитать дескрипторы по всему изображению с win_stride=(4,4) и потом рандомно выбрать 10 из них.\n",
    "Сделаем это так же в цикле для всех файлов из папки neg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_neg_images = \"INRIAPerson/Train/neg/\"\n",
    "onlyfiles = [f for f in listdir(path_to_neg_images) if isfile(join(path_to_neg_images, f))]\n",
    "descriptors_neg = list()\n",
    "\n",
    "win_stride = (4,4)\n",
    "\n",
    "for im in onlyfiles:\n",
    "    img  = cv2.imread(path_to_neg_images+im)\n",
    "    #получаем дескрипторы изображения и приводим их к рамеру\n",
    "    #(кол-во окон на изображении)х(рамер дескриптора одного окна)\n",
    "    #рамер дексриптора для параметров HOG как в статье - 3780\n",
    "    descriptor = hog.compute(img, win_stride).reshape(-1,3780)\n",
    "    indexes = np.random.randint(descriptor.shape[0], size=2)\n",
    "    ten_random_samples = descriptor[indexes]\n",
    "    descriptors_neg.extend(ten_random_samples)\n",
    "np.squeeze(descriptors_neg)\n",
    "descriptors_neg = np.stack(descriptors_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим маркеры, отвечающие за принадлежность к pos и neg папкам. Пусть pos - 1, а neg - 0. Тогда\n",
    "labels_pos = [1]*np.array(descriptors_pos).shape[0]\n",
    "labels_neg = [0]*np.array(descriptors_neg).shape[0]\n",
    "labels = np.array(labels_pos+labels_neg)\n",
    "\n",
    "features = descriptors_pos\n",
    "for i in descriptors_neg:\n",
    "    features = np.vstack([features, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Существует два способа дальнейшего развития событий. Мы можем использовать алгоритм svm из sklearn или из opencv\n",
    "Основной проблемой на данном этапе является правильное задание параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Обучим SVM от sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1e-06, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=10000,kernel=\"linear\",gamma=0.000001)\n",
    "clf.fit(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279720, 1)\n"
     ]
    }
   ],
   "source": [
    "win_stride = (8,8) #шаг скользящего окна в пикселях по ширине и высоте\n",
    "img = cv2.imread(\"INRIAPerson/Train/pos/crop_000010.png\")\n",
    "cv2.resize(img, (64,128), interpolation = cv2.INTER_AREA)\n",
    "height, width = img.shape[:2]\n",
    "locations = []\n",
    "for i in range(width//8):\n",
    "    locations.append((i*8, (height-128)//2))\n",
    "#locations = [((width-64)//2, (height-128)//2), (width-64, height-128)]\n",
    "lst_test = hog.compute(img, locations = locations)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(lst_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(height//128)\n",
    "print(width//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_test = lst_test.reshape(3780,lst_test.shape[0]//3780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.stack(lst_test)\n",
    "test_data = test_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(locations)):\n",
    "    if (pred[i] == 1):\n",
    "        img = cv2.rectangle(img,locations[i],(locations[i][0]+64,locations[i][1]+128),(255,255,0),3)\n",
    "        \n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.rectangle(img,locations[0],(locations[0][0]+64,locations[0][1]+128),(255,255,0),3)\n",
    "img = cv2.rectangle(img,locations[1],(locations[1][0]+64,locations[1][1]+128),(255,255,0),3)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. SVM от OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SVM for OpenCV 3\n",
    "svm = cv2.ml.SVM_create()\n",
    "# Set SVM type\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "# Set SVM Kernel to Radial Basis Function (RBF) \n",
    "svm.setKernel(cv2.ml.SVM_RBF)\n",
    "# Set parameter C\n",
    "C = 12.5\n",
    "svm.setC(C)\n",
    "# Set parameter Gamma\n",
    "gamma = 0.50625\n",
    "svm.setGamma(gamma)\n",
    " \n",
    "# Train SVM on training data  \n",
    "svm.train(features, cv2.ml.ROW_SAMPLE, labels)\n",
    " \n",
    "# Save trained model \n",
    "svm.save(\"digits_svm_model.yml\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем данные в файлы, чтобы позже работать с ними без детектирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = open('pos_detection.txt', 'w')\n",
    "f_2 = open('neg_detection.txt', 'w')\n",
    "\n",
    "for item in descriptors_pos:\n",
    "    for i in item:\n",
    "        f_1.write(str(i[0])+ \" \")\n",
    "    f_1.write('\\n')\n",
    "for item in descriptors_neg:\n",
    "    for i in item:\n",
    "        f_2.write(str(i)+ \" \")\n",
    "    f_2.write('\\n')\n",
    "    \n",
    "f_1.close()\n",
    "f_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "SVM классификатор\n",
    "Сначала задаём ему стандартные параметры, а потом используем метод detect()\n",
    "\n",
    "1. Как он работает? Что он делает?\n",
    "2. Какую роль играют те детекторы, которые мы обучали? Возможно, его можно/нужно обучить\n",
    "3. Прочитать другие статьи и, возможно, сделать по-другому\n",
    "4. Что он выдаёт. Если это координаты в 2D пространстве и его уверенность, то круть. Можно нарисовать график. Но тогда почему 2 признака?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные, чтобы с ними было удобно работать.\n",
    "Встаёт ещё вопрос, какой SVM брать: из opencv или sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog.setSVMDetector(hog.getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"INRIAPerson/Test/pos/crop001682.png\")\n",
    "a = hog.detectMultiScale(img)\n",
    "\n",
    "for i in range(len(a[0])):\n",
    "    img = cv2.rectangle(img,(a[0][i][0],a[0][i][1]) ,(a[0][i][2],a[0][i][3]),(255,255,0),3)\n",
    "    \n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполангется, что он возвращает вершины прямоугольника. Но по картинке это как-то не особо заметно. Или он плохо детектирует\n",
    "В общем, остются вопросы по поводу\n",
    "1. Как обучать его. Что он принимает? (Возможно, есть в курсах яндекса, если это svm от sklearn)\n",
    "2. Что он выдаёт? Ебала какая-то. Или он плохо настроен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_stride = (8,8) #шаг скользящего окна в пикселях по ширине и высоте\n",
    "path_to_image = \"INRIAPerson/Test/pos/crop_000001.png\"\n",
    "img = cv2.imread(path_to_image)\n",
    "descriptor_ = hog.compute(img, win_stride)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3780, 1)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"INRIAPerson/Test/pos/crop_000001.png\")\n",
    "height, width = img.shape[:2]\n",
    "locations = [((width-64)//2, (height-128)//2)]\n",
    "descriptor_ = hog.compute(img, locations=locations)\n",
    "print(descriptor_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-6c0285f9d232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test on a held out test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtestResponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptor_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "# Test on a held out test set\n",
    "testResponse = svm.predict(descriptor_)[1].ravel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
