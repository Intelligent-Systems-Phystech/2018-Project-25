{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### надо установить opencv для python, если не установлен.\n",
    "#### pip(pip3) install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример получения вектора признаков для изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# далее задаются параметры HOG-a, они выставлены как в статье.\n",
    "win_size = (64,128) \n",
    "block_size = (16,16)\n",
    "block_stride = (8,8)\n",
    "cell_size = (8,8)\n",
    "nbins = 9\n",
    "deriv_aperture = 1\n",
    "win_sigma = -1\n",
    "histogram_norm_type = 0\n",
    "l2_hys_threshold = 2.0000000000000001e-01\n",
    "gamma_correction = 0\n",
    "nlevels = 64\n",
    "hog = cv2.HOGDescriptor(win_size,block_size,block_stride,cell_size,nbins,deriv_aperture,win_sigma,\n",
    "                        histogram_norm_type,l2_hys_threshold,gamma_correction,nlevels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В базе INRIA размер изображений содержащих пешеходов  - 96х160(train) и 70x134(test). Человек расположен по центру.\n",
    "\n",
    "Вам нужно получить вектор признаков(дескриптор) для окна 64х128. По умолчанию compute() строит дескрипторы для всех окон размером 64х128 методом скользящего окна, с шагом win_stride по обеим осям. Но если вам нужно получить дескриптор только для одного окна 64х128, то у метода есть аргумент locations, в котором можно передать координаты верхнего левого угла интересующего вас окна (либо список таких координат)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, для изображений из train извлечение центрального окна 64х128 выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3780"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"crop_000010.png\")\n",
    "height, width = img.shape[:2]\n",
    "locations = [((width-64)//2, (height-128)//2)]\n",
    "descriptor = hog.compute(img, locations=locations)\n",
    "descriptor.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения фона(отрицательные примеры)  - изображения произвольного размера. В обучающей выборке их 1218. Авторы HOG для обучения выбирали рандомно 10 окон 64х128 из каждого изображения  - всего 12180 примеров, не содержащих пешеходов.\n",
    "\n",
    "Для этого, например, можно посчитать дескрипторы по всему изображению с win_stride=(4,4) и потом рандомно выбрать 10 из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие манипуляции вам надо проделать в цикле со всеми изображениями из train: для изображений из папки pos/ выбирать центральное окно, а из папки neg/ - 10 рандомных окон. Собрать их в np.array  или список, как вам будет удобно ну и в файл сохранить тоже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы получить ответ svm классификатора у класса HOGDescriptor есть метод detect(). Этот метод вам понадобится, чтобы строить кривые качества (DET кривые). Метод detect() работает похожим образом с compute().\n",
    "Только перед его использованием нужно задать веса SVM:\n",
    "\n",
    "    hog.setSVMDetector(hog.getDefaultPeopleDetector()) - используется веса из opencv для HOG, обученного на INRIA\n",
    "В остальном поробуйте сами с detect() разобраться. Если не получится - пишите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гайд по построению DET кривых позже добавлю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выделим признаки на позитивных картинках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_stride = (8,8) #шаг скользящего окна в пикселях по ширине и высоте\n",
    "def imHOG(path_to_image):\n",
    "    img = cv2.imread(path_to_image)\n",
    "    height, width = img.shape[:2]\n",
    "    locations = [((width-64)//2, (height-128)//2)]\n",
    "    descriptor = hog.compute(img, locations=locations)\n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "images = open(\"pos.lst\")\n",
    "string = images.read()\n",
    "images = string.split(\"\\n\")\n",
    "for i in range(len(images)):\n",
    "    images[i] = images[i][10:]\n",
    "images = images[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "for i in range(len(images)):\n",
    "    #desc_file.write(str(imHOG(images[i]))+\"\\n\")\n",
    "    descriptor_current = imHOG(images[i])\n",
    "    pos.append(descriptor_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = open(\"pos_test.lst\")\n",
    "string = images.read()\n",
    "images = string.split(\"\\n\")\n",
    "for i in range(len(images)):\n",
    "    images[i] = images[i][9:]\n",
    "images = images[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test = []\n",
    "for i in range(len(images)):\n",
    "    #desc_file.write(str(imHOG(images[i]))+\"\\n\")\n",
    "    descriptor_current = imHOG(images[i])\n",
    "    pos_test.append(descriptor_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# На негативных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_stride = (8,8) #шаг скользящего окна в пикселях по ширине и высоте\n",
    "def imHOG_neg(path_to_image):\n",
    "    img = cv2.imread(path_to_image)\n",
    "    win_stride = (4,4)\n",
    "    #получаем дескрипторы изображения и приводим их к рамеру\n",
    "    #(кол-во окон на изображении)х(рамер дескриптора одного окна)\n",
    "    #рамер дексриптора для параметров HOG как в статье - 3780\n",
    "    descriptors = hog.compute(img, win_stride).reshape(-1,3780)\n",
    "    indexes = np.random.randint(descriptors.shape[0], size=10)\n",
    "    ten_random_samples = descriptors[indexes]\n",
    "    return ten_random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_neg = open(\"neg.lst\")\n",
    "string_neg = images_neg.read()\n",
    "images_neg = string_neg.split(\"\\n\")\n",
    "for i in range(len(images_neg)):\n",
    "    images_neg[i] = images_neg[i][10:]\n",
    "images_neg = images_neg[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = []\n",
    "for i in range(len(images_neg)):\n",
    "    desc_hog = imHOG(images_neg[i])\n",
    "    neg.append(descriptor_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_neg = open(\"neg_test.lst\")\n",
    "string_neg = images_neg.read()\n",
    "images_neg = string_neg.split(\"\\n\")\n",
    "for i in range(len(images_neg)):\n",
    "    images_neg[i] = images_neg[i][9:]\n",
    "images_neg = images_neg[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test = []\n",
    "for i in range(len(images_neg)):\n",
    "    desc_hog = imHOG(images_neg[i])\n",
    "    neg_test.append(descriptor_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решейпим полученные дескриаторы pos, pos_test, neg, neg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.array(pos)\n",
    "pos_test = np.array(pos_test)\n",
    "neg = np.array(neg)\n",
    "neg_test = np.array(neg_test)\n",
    "\n",
    "\n",
    "\n",
    "def reshape(matrix):\n",
    "    l = matrix.shape[0]\n",
    "    new_matrix = []\n",
    "    cur = []\n",
    "    for i in range(l):\n",
    "        for j in range(3780):\n",
    "            cur.append(matrix[i][j][0])\n",
    "        new_matrix.append(cur)\n",
    "        cur = []\n",
    "    return new_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reshape = reshape(neg)\n",
    "pos_reshape = reshape(pos)\n",
    "pos_test_reshape = reshape(pos_test)\n",
    "neg_test_reshape = reshape(neg_test)\n",
    "neg_reshape = reshape_9_30_14(neg_reshape)\n",
    "pos_reshape = reshape_9_30_14(pos_reshape)\n",
    "pos_test_reshape = reshape_9_30_14(pos_test)\n",
    "neg_test_reshape = reshape_9_30_14(neg_test_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В каждом массиве хранятся векторы длины 3180. Построим сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reshape(matrix):\n",
    "    l = matrix.shape[0]\n",
    "    new_matrix = []\n",
    "    cur = []\n",
    "    for i in range(l):\n",
    "        for j in range(3780):\n",
    "            cur.append(matrix[i][j][0])\n",
    "        new_matrix.append(cur)\n",
    "        cur = []\n",
    "    return new_matrix\n",
    "def res_matr(descriptors):\n",
    "    pos = np.array(descriptors)\n",
    "    pos_reshape = reshape(pos)\n",
    "    matr=[]\n",
    "    for i in range(0,len(pos_reshape)):\n",
    "        \n",
    "        m_i=[]\n",
    "        for j in range(0,15):\n",
    "            q1=[]\n",
    "            q2=[]\n",
    "            for k in range(0,7):\n",
    "                q1.append(pos_reshape[i][36*j*7+2*k*18:36*j*7+2*k*18+9])\n",
    "                q1.append(pos_reshape[i][36*j*7+2*k*18+9:36*j*7+2*k*18+18])\n",
    "                q2.append(pos_reshape[i][36*j*7+2*k*18+18:36*j*7+2*k*18+27])\n",
    "                q2.append(pos_reshape[i][36*j*7+2*k*18+27:36*j*7+2*k*18+36])\n",
    "            m_i.append(q1)\n",
    "            m_i.append(q2)\n",
    "        matr.append(m_i)\n",
    "    return matr\n",
    "\n",
    "\n",
    "def image_descr(mas,q,l):\n",
    "    r=[]\n",
    "    for i in range(0,30):\n",
    "        for j in range (0,14):\n",
    "            r=r+[mas[q][i][j][l]]\n",
    "    r=np.array(r).reshape(14,30)\n",
    "    #plt.imshow(r)\n",
    "    return r\n",
    "\n",
    "def reshape_9_30_14(mas):\n",
    "    W=[]\n",
    "    for i in range(len(mas)):\n",
    "        W_i=[]\n",
    "        for k in range(0,9):\n",
    "            r=image_descr(mas,i,k)\n",
    "            W_i.append(r)\n",
    "        W.append(W_i)\n",
    "    return W\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_f=res_matr(neg)\n",
    "pos_f=res_matr(pos)\n",
    "neg_test_f=res_matr(neg_test)\n",
    "pos_test_f=res_matr(pos_test)\n",
    "neg_reshape_9 = reshape_9_30_14(neg_f)\n",
    "pos_reshape_9 = reshape_9_30_14(pos_f)\n",
    "pos_test_reshape_9 = reshape_9_30_14(pos_test_f)\n",
    "neg_test_reshape_9 = reshape_9_30_14(neg_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reshape_9[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \"\"\"Custom module for a simple convnet classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(9, 18, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(18, 36, kernel_size=3)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(3*144, 40)\n",
    "        self.fc2 = nn.Linear(40, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input is 30x14x9\n",
    "        # conv1(kernel=3, filters=9) 30x14x18 -> 28x12x18\n",
    "        # max_pool(kernel=2) 28x12x18 -> 14x6x18\n",
    "        \n",
    "        # Do not be afraid of F's - those are just functional wrappers for modules form nn package\n",
    "        # Please, see for yourself - http://pytorch.org/docs/_modules/torch/nn/functional.html\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        \n",
    "        # conv2(kernel=3, filters=36) 14x6x18 -> 12x4x36\n",
    "        # max_pool(kernel=2) 12x4x36 -> 6x2x36\n",
    "        x = F.relu(F.max_pool2d(self.dropout(self.conv2(x)), 2))\n",
    "        \n",
    "        # flatten 6x2x36 = 3*144\n",
    "        x = x.view(-1, 3*144)\n",
    "        \n",
    "        # 3*144 -> 40\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # 40 -> 2\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # transform to logits\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "# create classifier and optimizer objects\n",
    "clf = CNNClassifier()\n",
    "opt = torch.optim.Adam(clf.parameters(), lr=1e-3)\n",
    "\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "avg_loss = []\n",
    "\n",
    "def train(epoch):\n",
    "    clf.train() # set model in training mode (need this because of dropout)\n",
    "    \n",
    "    # dataset API gives us pythonic batching \n",
    "    for batch_id in range(60):\n",
    "        #positive\n",
    "        data = Variable(torch.tensor(pos_f[10*batch_id:10*(batch_id+1)], dtype=torch.float32))\n",
    "        data = torch.reshape(data, [10,9,30,14])\n",
    "        target = Variable(torch.tensor(np.ones(10), dtype=torch.long))\n",
    "        target = torch.reshape(target, [10])\n",
    "        # forward pass, calculate loss and backprop!\n",
    "        opt.zero_grad()\n",
    "        preds = clf(data)\n",
    "        loss = F.nll_loss(preds, target)\n",
    "        loss.backward()\n",
    "        loss_history.append(loss.data[0])\n",
    "        opt.step()\n",
    "        \n",
    "        #negative\n",
    "        data = Variable(torch.tensor(neg_f[10*batch_id:10*(batch_id+1)], dtype=torch.float32))\n",
    "        data = torch.reshape(data, [10,9,30,14])\n",
    "        target = Variable(torch.tensor(np.zeros(10), dtype=torch.long))\n",
    "        target = torch.reshape(target, [10])\n",
    "        # forward pass, calculate loss and backprop!\n",
    "        opt.zero_grad()\n",
    "        preds = clf(data)\n",
    "        loss = F.nll_loss(preds, target)\n",
    "        loss.backward()\n",
    "        loss_history.append(loss.data[0])\n",
    "        opt.step()\n",
    "        \n",
    "        if batch_id % 10 == 0:\n",
    "            print(loss.data[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "def test(epoch):\n",
    "    clf.eval() # set model in inference mode (need this because of dropout)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_id in range(20):\n",
    "        #negative\n",
    "        data = Variable(torch.tensor(neg_test_f[10*batch_id:10*(batch_id+1)], dtype=torch.float32))\n",
    "        data = torch.reshape(data, [10,9,30,14])\n",
    "        target = Variable(torch.tensor(np.zeros(10), dtype=torch.long))\n",
    "        target = torch.reshape(target, [10])\n",
    "        \n",
    "        output = clf(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        print(\"Neg {}\".format(pred), output)\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        #positive\n",
    "        data = Variable(torch.tensor(pos_test_f[10*batch_id:10*(batch_id+1)], dtype=torch.float32))\n",
    "        data = torch.reshape(data, [10,9,30,14])\n",
    "        target = Variable(torch.tensor(np.ones(10), dtype=torch.long))\n",
    "        target = torch.reshape(target, [10])\n",
    "        \n",
    "        output = clf(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        print(\"Pos {}\".format(pred), output)\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        \n",
    "        \n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= 200 # loss function already averages over batch size\n",
    "    accuracy = 100. * correct / 200\n",
    "    acc_history.append(accuracy)\n",
    "    avg_loss.append(test_loss)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, 400,\n",
    "        accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:83: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7221)\n",
      "tensor(0.7147)\n",
      "tensor(0.7531)\n",
      "tensor(0.7688)\n",
      "tensor(0.6528)\n",
      "tensor(0.5046)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:115: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-3.8455, -0.0216],\n",
      "        [-1.6307, -0.2179],\n",
      "        [-3.2741, -0.0386],\n",
      "        [-2.5626, -0.0802],\n",
      "        [-2.8019, -0.0626],\n",
      "        [-2.4027, -0.0948],\n",
      "        [-3.7506, -0.0238],\n",
      "        [-1.3505, -0.2999],\n",
      "        [-4.2611, -0.0142],\n",
      "        [-1.8704, -0.1673]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.6800, -0.2063],\n",
      "        [-2.2490, -0.1115],\n",
      "        [-2.8178, -0.0616],\n",
      "        [-1.5522, -0.2380],\n",
      "        [-1.9336, -0.1562],\n",
      "        [-3.4974, -0.0307],\n",
      "        [-2.8015, -0.0626],\n",
      "        [-1.8274, -0.1753],\n",
      "        [-3.9914, -0.0186],\n",
      "        [-4.3995, -0.0124]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-3.0275, -0.0496],\n",
      "        [-2.0244, -0.1417],\n",
      "        [-1.7502, -0.1908],\n",
      "        [-2.8448, -0.0599],\n",
      "        [-3.8622, -0.0212],\n",
      "        [-4.5171, -0.0110],\n",
      "        [-4.2239, -0.0147],\n",
      "        [-2.3608, -0.0991],\n",
      "        [-3.7804, -0.0231],\n",
      "        [-2.5334, -0.0827]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.9041, -0.1613],\n",
      "        [-3.7476, -0.0239],\n",
      "        [-1.5445, -0.2401],\n",
      "        [-1.4984, -0.2529],\n",
      "        [-3.8408, -0.0217],\n",
      "        [-4.0070, -0.0184],\n",
      "        [-4.8754, -0.0077],\n",
      "        [-2.4933, -0.0862],\n",
      "        [-2.1049, -0.1300],\n",
      "        [-2.4047, -0.0946]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-4.0370, -0.0178],\n",
      "        [-2.8069, -0.0623],\n",
      "        [-5.2314, -0.0054],\n",
      "        [-1.9479, -0.1538],\n",
      "        [-2.6608, -0.0725],\n",
      "        [-2.9169, -0.0556],\n",
      "        [-3.3849, -0.0345],\n",
      "        [-3.7778, -0.0231],\n",
      "        [-5.3626, -0.0047],\n",
      "        [-4.0422, -0.0177]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.3626, -0.0989],\n",
      "        [-2.6833, -0.0708],\n",
      "        [-3.0748, -0.0473],\n",
      "        [-4.6553, -0.0096],\n",
      "        [-1.8110, -0.1785],\n",
      "        [-2.6551, -0.0729],\n",
      "        [-4.9070, -0.0074],\n",
      "        [-1.7777, -0.1852],\n",
      "        [-2.0545, -0.1371],\n",
      "        [-4.3363, -0.0132]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.7234, -0.1966],\n",
      "        [-3.9155, -0.0201],\n",
      "        [-3.0397, -0.0490],\n",
      "        [-2.2537, -0.1109],\n",
      "        [-2.7030, -0.0694],\n",
      "        [-3.3826, -0.0345],\n",
      "        [-2.4733, -0.0881],\n",
      "        [-5.6841, -0.0034],\n",
      "        [-3.8281, -0.0220],\n",
      "        [-3.3530, -0.0356]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.8878, -0.1642],\n",
      "        [-3.7303, -0.0243],\n",
      "        [-1.7976, -0.1812],\n",
      "        [-4.5000, -0.0112],\n",
      "        [-4.1212, -0.0164],\n",
      "        [-3.3055, -0.0374],\n",
      "        [-2.8303, -0.0608],\n",
      "        [-3.1647, -0.0431],\n",
      "        [-2.3682, -0.0983],\n",
      "        [-2.5300, -0.0830]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.5891, -0.0781],\n",
      "        [-3.2847, -0.0382],\n",
      "        [-4.0494, -0.0176],\n",
      "        [-3.3120, -0.0371],\n",
      "        [-2.5105, -0.0847],\n",
      "        [-2.5486, -0.0814],\n",
      "        [-2.0944, -0.1314],\n",
      "        [-3.6008, -0.0277],\n",
      "        [-3.8356, -0.0218],\n",
      "        [-4.0688, -0.0172]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-4.0862, -0.0169],\n",
      "        [-2.3167, -0.1038],\n",
      "        [-2.0753, -0.1341],\n",
      "        [-2.6017, -0.0770],\n",
      "        [-4.0520, -0.0175],\n",
      "        [-4.1500, -0.0159],\n",
      "        [-3.7221, -0.0245],\n",
      "        [-1.8760, -0.1663],\n",
      "        [-2.2530, -0.1110],\n",
      "        [-2.2918, -0.1066]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.7274, -0.0676],\n",
      "        [-1.7060, -0.2004],\n",
      "        [-2.8146, -0.0618],\n",
      "        [-2.1672, -0.1216],\n",
      "        [-2.0509, -0.1377],\n",
      "        [-2.3300, -0.1024],\n",
      "        [-2.7873, -0.0636],\n",
      "        [-2.6918, -0.0702],\n",
      "        [-1.8943, -0.1630],\n",
      "        [-3.1447, -0.0440]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.8004, -0.0627],\n",
      "        [-2.6270, -0.0750],\n",
      "        [-2.1976, -0.1177],\n",
      "        [-2.9318, -0.0548],\n",
      "        [-2.4467, -0.0906],\n",
      "        [-4.3866, -0.0125],\n",
      "        [-1.6901, -0.2040],\n",
      "        [-2.2263, -0.1142],\n",
      "        [-3.5162, -0.0302],\n",
      "        [-2.2634, -0.1098]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.2590, -0.3340],\n",
      "        [-1.1847, -0.3650],\n",
      "        [-2.0192, -0.1424],\n",
      "        [-2.6976, -0.0697],\n",
      "        [-2.3942, -0.0957],\n",
      "        [-2.6716, -0.0717],\n",
      "        [-3.0458, -0.0487],\n",
      "        [-3.0625, -0.0479],\n",
      "        [-4.2362, -0.0146],\n",
      "        [-2.0784, -0.1337]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.8963, -0.0568],\n",
      "        [-3.2204, -0.0408],\n",
      "        [-2.7042, -0.0693],\n",
      "        [-3.0492, -0.0486],\n",
      "        [-2.1667, -0.1217],\n",
      "        [-2.5546, -0.0809],\n",
      "        [-2.7997, -0.0628],\n",
      "        [-2.3328, -0.1021],\n",
      "        [-2.6594, -0.0726],\n",
      "        [-1.8300, -0.1748]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.7999, -0.1807],\n",
      "        [-2.1077, -0.1296],\n",
      "        [-2.2530, -0.1110],\n",
      "        [-3.0218, -0.0499],\n",
      "        [-3.1794, -0.0425],\n",
      "        [-3.2368, -0.0401],\n",
      "        [-2.2467, -0.1118],\n",
      "        [-2.6406, -0.0740],\n",
      "        [-3.6980, -0.0251],\n",
      "        [-3.1172, -0.0453]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-3.2335, -0.0402],\n",
      "        [-2.0592, -0.1364],\n",
      "        [-2.6395, -0.0741],\n",
      "        [-2.9550, -0.0535],\n",
      "        [-2.2239, -0.1145],\n",
      "        [-1.5934, -0.2272],\n",
      "        [-2.7435, -0.0665],\n",
      "        [-3.7591, -0.0236],\n",
      "        [-3.5303, -0.0297],\n",
      "        [-2.3845, -0.0967]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.4051, -0.0946],\n",
      "        [-1.5190, -0.2471],\n",
      "        [-2.5555, -0.0808],\n",
      "        [-3.8587, -0.0213],\n",
      "        [-2.7942, -0.0631],\n",
      "        [-1.0652, -0.4226],\n",
      "        [-1.8837, -0.1649],\n",
      "        [-3.8309, -0.0219],\n",
      "        [-3.8963, -0.0205],\n",
      "        [-1.4542, -0.2660]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-2.3514, -0.1001],\n",
      "        [-2.4685, -0.0885],\n",
      "        [-2.3167, -0.1038],\n",
      "        [-3.2192, -0.0408],\n",
      "        [-2.9510, -0.0537],\n",
      "        [-3.9926, -0.0186],\n",
      "        [-3.2870, -0.0381],\n",
      "        [-2.5284, -0.0832],\n",
      "        [-2.2452, -0.1119],\n",
      "        [-3.7813, -0.0231]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-1.7343, -0.1942],\n",
      "        [-3.6289, -0.0269],\n",
      "        [-2.2430, -0.1122],\n",
      "        [-3.1362, -0.0444],\n",
      "        [-3.3188, -0.0369],\n",
      "        [-2.1394, -0.1252],\n",
      "        [-1.8391, -0.1731],\n",
      "        [-2.6434, -0.0738],\n",
      "        [-2.5659, -0.0800],\n",
      "        [-2.4560, -0.0897]], grad_fn=<LogSoftmaxBackward>)\n",
      "Neg tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364],\n",
      "        [-0.2715, -1.4364]], grad_fn=<LogSoftmaxBackward>)\n",
      "Pos tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) tensor([[-3.6756, -0.0257],\n",
      "        [-1.3906, -0.2863],\n",
      "        [-3.7353, -0.0242],\n",
      "        [-2.6463, -0.0736],\n",
      "        [-2.7145, -0.0685],\n",
      "        [-2.6250, -0.0752],\n",
      "        [-2.6769, -0.0713],\n",
      "        [-2.1233, -0.1274],\n",
      "        [-2.0590, -0.1365],\n",
      "        [-2.7333, -0.0672]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "Test set: Average loss: 0.0359, Accuracy: 400/400 (200%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(0)\n",
    "test(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3211) 0.18128979\n"
     ]
    }
   ],
   "source": [
    "data = Variable(torch.tensor(pos_f[0:10], dtype=torch.float32))\n",
    "#data = torch.reshape(data, [10,30,14,9])\n",
    "data = torch.reshape(data, [10,9,30,14])\n",
    "print(data[0][1][5][5], pos_f[0][5][5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "tensor(0.2460)\n",
      "tensor(0.1251)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:83: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0713)\n",
      "tensor(0.0133)\n",
      "tensor(0.0033)\n",
      "tensor(0.0165)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/tomininvladislav/env/lib/python3.6/site-packages/ipykernel_launcher.py:114: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 1\n",
      "tensor(0.0153)\n",
      "tensor(0.0058)\n",
      "tensor(0.0133)\n",
      "tensor(0.0047)\n",
      "tensor(0.0038)\n",
      "tensor(0.0194)\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 2\n",
      "tensor(0.0030)\n",
      "tensor(0.0040)\n",
      "tensor(0.0066)\n",
      "tensor(0.0049)\n",
      "tensor(0.0015)\n",
      "tensor(0.0014)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 3\n",
      "tensor(0.0052)\n",
      "tensor(0.0011)\n",
      "tensor(0.0009)\n",
      "tensor(0.0038)\n",
      "tensor(0.0046)\n",
      "tensor(0.0009)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 4\n",
      "tensor(0.0035)\n",
      "tensor(0.0009)\n",
      "tensor(0.0033)\n",
      "tensor(0.0006)\n",
      "tensor(0.0001)\n",
      "tensor(0.0000)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 5\n",
      "tensor(0.0020)\n",
      "tensor(0.0010)\n",
      "tensor(0.0001)\n",
      "tensor(0.0004)\n",
      "tensor(0.0006)\n",
      "tensor(0.0077)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 6\n",
      "tensor(0.0050)\n",
      "tensor(0.0016)\n",
      "tensor(0.0001)\n",
      "tensor(0.0046)\n",
      "tensor(0.0020)\n",
      "tensor(0.0132)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 7\n",
      "tensor(0.0002)\n",
      "tensor(0.0061)\n",
      "tensor(0.0023)\n",
      "tensor(0.0017)\n",
      "tensor(0.0001)\n",
      "tensor(0.0001)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 8\n",
      "tensor(0.0009)\n",
      "tensor(0.0001)\n",
      "tensor(3.8147e-06)\n",
      "tensor(0.0779)\n",
      "tensor(0.0001)\n",
      "tensor(3.2425e-06)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n",
      "Epoch 9\n",
      "tensor(0.0005)\n",
      "tensor(0.0211)\n",
      "tensor(0.0002)\n",
      "tensor(4.2915e-06)\n",
      "tensor(0.0002)\n",
      "tensor(0.0018)\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 400/400 (200%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 10):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
